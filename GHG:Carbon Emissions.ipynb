{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "663e1997",
   "metadata": {},
   "source": [
    "### Data Importation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1085a64-6fd3-4164-a2cb-c8ae6b4ee666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded GHG dataset from https://raw.githubusercontent.com/datasets/co2-fossil-global/master/global.csv\n",
      "Initial GHG data columns: ['Year', 'Total', 'Gas Fuel', 'Liquid Fuel', 'Solid Fuel', 'Cement', 'Gas Flaring', 'Per Capita']\n",
      "Initial GHG data shape: (260, 8)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# Define the analysis period for filtering\n",
    "START_YEAR = 2015\n",
    "END_YEAR = 2025\n",
    "\n",
    "# Attempt to load a static GHG dataset robustly\n",
    "# (Using the stable alternative since the signed URL can expire)\n",
    "alt_url = \"https://raw.githubusercontent.com/datasets/co2-fossil-global/master/global.csv\"\n",
    "\n",
    "try:\n",
    "    # Use the stable public dataset (global.csv)\n",
    "    ghg_data = pd.read_csv(alt_url)\n",
    "    print(f\"Loaded GHG dataset from {alt_url}\")\n",
    "except Exception as e_alt:\n",
    "    print(f\"Fallback source failed: {e_alt}. Creating a minimal sample dataset.\")\n",
    "    ghg_data = pd.DataFrame({\n",
    "        'Country': ['USA', 'China', 'India', 'USA'],\n",
    "        'Year': [2018, 2019, 2019, 2019],\n",
    "        'Annual CO₂ emissions': [5000, 10000, 2500, 5100] # Use the actual column name from the fallback\n",
    "    })\n",
    "\n",
    "# Standardize columns to simplify downstream code\n",
    "rename_dict = {}\n",
    "for col in ghg_data.columns:\n",
    "    if 'Country' in col or 'Entity' in col:\n",
    "        rename_dict[col] = 'Country'\n",
    "    elif 'Year' in col:\n",
    "        rename_dict[col] = 'Year'\n",
    "    elif 'emissions' in col or 'Emissions' in col:\n",
    "        rename_dict[col] = 'Emissions_kt'\n",
    "\n",
    "ghg_data.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "# Keep only essential columns\n",
    "if all(col in ghg_data.columns for col in ['Country', 'Year', 'Emissions_kt']):\n",
    "    ghg_data = ghg_data[['Country', 'Year', 'Emissions_kt']].copy()\n",
    "    \n",
    "print(\"Initial GHG data columns:\", ghg_data.columns.tolist())\n",
    "print(f\"Initial GHG data shape: {ghg_data.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4994ae79",
   "metadata": {},
   "source": [
    "# Data Cleaning and Filtering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb51b177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No emissions-like column found; created 'Emissions_kt' with NaN values.\n",
      "Warning: ghg_data is empty after dropping NaNs for 'Year' and 'Emissions_kt'.\n",
      "\n",
      "--- Step 2: Cleaned and Filtered GHG Data ---\n",
      "Remaining rows after cleanup: 0\n",
      "| Year   | Total   | Gas Fuel   | Liquid Fuel   | Solid Fuel   | Cement   | Gas Flaring   | Per Capita   | Emissions_kt   |\n",
      "|--------|---------|------------|---------------|--------------|----------|---------------|--------------|----------------|\n"
     ]
    }
   ],
   "source": [
    "# --- Clean Data Types and Filter Years ---\n",
    "\n",
    "# Ensure there is a usable emissions column: try to locate candidate columns and normalize to 'Emissions_kt'\n",
    "if 'Emissions_kt' not in ghg_data.columns:\n",
    "\t# Prefer columns that contain 'annual' + 'co2' / 'emiss' or direct emission-like names\n",
    "\tcandidates = []\n",
    "\tfor col in ghg_data.columns:\n",
    "\t\tlc = str(col).lower()\n",
    "\t\tif 'annual' in lc and ('co2' in lc or 'co₂' in lc or 'emiss' in lc):\n",
    "\t\t\tcandidates.append(col)\n",
    "\t\telif 'emiss' in lc and 'per' not in lc:\n",
    "\t\t\tcandidates.append(col)\n",
    "\t\telif lc in ('co2', 'co2_kt', 'emissions', 'total_co2'):\n",
    "\t\t\tcandidates.append(col)\n",
    "\t# fallback: any column containing 'co2' (may pick the most relevant available)\n",
    "\tif not candidates:\n",
    "\t\tany_co2 = [col for col in ghg_data.columns if 'co2' in str(col).lower() or 'co₂' in str(col).lower()]\n",
    "\t\tcandidates = any_co2\n",
    "\n",
    "\tif candidates:\n",
    "\t\tchosen = candidates[0]\n",
    "\t\tghg_data.rename(columns={chosen: 'Emissions_kt'}, inplace=True)\n",
    "\t\tprint(f\"Renamed '{chosen}' -> 'Emissions_kt' for cleaning.\")\n",
    "\telse:\n",
    "\t\t# If nothing sensible was found, create the column to avoid KeyError (it will be NaN)\n",
    "\t\tghg_data['Emissions_kt'] = np.nan\n",
    "\t\tprint(\"No emissions-like column found; created 'Emissions_kt' with NaN values.\")\n",
    "\n",
    "# 1. Clean 'Emissions_kt' column\n",
    "# Clean out common non-numeric characters before conversion\n",
    "ghg_data['Emissions_kt'] = ghg_data['Emissions_kt'].astype(str).str.replace(',', '', regex=False).str.replace(' ', '', regex=False)\n",
    "ghg_data['Emissions_kt'] = ghg_data['Emissions_kt'].replace(['-', '..', 'NA', 'None', ''], np.nan)\n",
    "ghg_data['Emissions_kt'] = pd.to_numeric(ghg_data['Emissions_kt'], errors='coerce')\n",
    "\n",
    "# 2. Clean 'Year' column\n",
    "if 'Year' in ghg_data.columns:\n",
    "\tghg_data['Year'] = pd.to_numeric(ghg_data['Year'], errors='coerce').astype('Int64')\n",
    "else:\n",
    "\t# try common alternatives\n",
    "\tyear_candidates = [c for c in ghg_data.columns if 'year' in str(c).lower()]\n",
    "\tif year_candidates:\n",
    "\t\tghg_data.rename(columns={year_candidates[0]: 'Year'}, inplace=True)\n",
    "\t\tghg_data['Year'] = pd.to_numeric(ghg_data['Year'], errors='coerce').astype('Int64')\n",
    "\t\tprint(f\"Renamed '{year_candidates[0]}' -> 'Year' for cleaning.\")\n",
    "\telse:\n",
    "\t\tghg_data['Year'] = pd.NA\n",
    "\t\tprint(\"No 'Year' column found; created 'Year' with NA values.\")\n",
    "\n",
    "# 3. Drop genuine missing values and filter years\n",
    "ghg_data.dropna(subset=['Year', 'Emissions_kt'], inplace=True)\n",
    "if not ghg_data.empty:\n",
    "\tghg_data = ghg_data[(ghg_data['Year'] >= START_YEAR) & (ghg_data['Year'] <= END_YEAR)].copy()\n",
    "else:\n",
    "\tprint(\"Warning: ghg_data is empty after dropping NaNs for 'Year' and 'Emissions_kt'.\")\n",
    "\n",
    "print(\"\\n--- Step 2: Cleaned and Filtered GHG Data ---\")\n",
    "print(f\"Remaining rows after cleanup: {len(ghg_data)}\")\n",
    "# to_markdown can fail if not available; guard with fallback\n",
    "try:\n",
    "\tprint(ghg_data.head().to_markdown(index=False))\n",
    "except Exception:\n",
    "\tprint(ghg_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3647a992",
   "metadata": {},
   "source": [
    "# Transformation to a Macro Carbon Factor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f6322e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 3: Macro Carbon Factor (Annual Growth Rate) ---\n",
      "| Year   | GHG_Growth_Factor   |\n",
      "|--------|---------------------|\n"
     ]
    }
   ],
   "source": [
    "# 1. Find the total global emissions for each year\n",
    "global_emissions_annual = ghg_data.groupby('Year')['Emissions_kt'].sum().reset_index()\n",
    "\n",
    "# 2. Calculate the annual growth rate (percentage change)\n",
    "# This represents the yearly shock/change in global carbon output.\n",
    "global_emissions_annual['GHG_Growth_Factor'] = global_emissions_annual['Emissions_kt'].pct_change()\n",
    "\n",
    "# 3. Clean up the resulting factor series\n",
    "macro_ghg_factor_annual = global_emissions_annual.set_index('Year')['GHG_Growth_Factor'].dropna()\n",
    "\n",
    "print(\"\\n--- Step 3: Macro Carbon Factor (Annual Growth Rate) ---\")\n",
    "print(macro_ghg_factor_annual.to_markdown(numalign=\"left\", stralign=\"left\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a87d800",
   "metadata": {},
   "source": [
    "# Daily Alignment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "382f3804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 4: Daily Aligned GHG Factor (First 10 Days of 2016) ---\n",
      "Note how the value is constant until the next annual figure.\n",
      "| 0   |\n",
      "|-----|\n"
     ]
    }
   ],
   "source": [
    "# --- Prepare to align with daily data ---\n",
    "\n",
    "# 1. Convert the annual factor index (Year) to the last day of the year\n",
    "# We use December 31st for the corresponding year.\n",
    "ghg_factor_daily_index = pd.to_datetime(macro_ghg_factor_annual.index.astype(str) + '-12-31')\n",
    "\n",
    "# 2. Create a daily series indexed by the year-end date\n",
    "ghg_factor_daily = pd.Series(macro_ghg_factor_annual.values, index=ghg_factor_daily_index)\n",
    "\n",
    "# 3. Reindex the series to cover the full range of your analysis, and use FFILL.\n",
    "# FFILL (Forward Fill) carries the annual change forward until the next year's change is available.\n",
    "FULL_DATE_RANGE = pd.date_range(start='2015-01-01', end='2025-10-31', freq='D')\n",
    "ghg_factor_daily_aligned = ghg_factor_daily.reindex(FULL_DATE_RANGE).ffill()\n",
    "\n",
    "# We need to trim off any NaNs remaining at the start (if the first year is missing a growth rate)\n",
    "ghg_factor_daily_aligned.dropna(inplace=True)\n",
    "\n",
    "print(\"\\n--- Step 4: Daily Aligned GHG Factor (First 10 Days of 2016) ---\")\n",
    "print(\"Note how the value is constant until the next annual figure.\")\n",
    "print(ghg_factor_daily_aligned.head(10).to_markdown(numalign=\"left\", stralign=\"left\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25eaac7",
   "metadata": {},
   "source": [
    "# Saved GHG_macro csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08bea1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ghg_macro.csv\n"
     ]
    }
   ],
   "source": [
    "macro_ghg_factor_annual.to_csv(\"ghg_macro.csv\")\n",
    "print(\"Saved ghg_macro.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
